{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze XML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pairs:  1979\n",
      "pair_ids:  1979\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('meta.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "xml_pairs_el = []\n",
    "\n",
    "for docs in root.iter('document'):\n",
    "    for sent in docs.iter('sentence'):\n",
    "        entities = {el.get('id'): el.get('text') for el in sent.findall('entity')}\n",
    "        for pair in sent.findall('pair'):\n",
    "            pair.set('sentence', sent.get('text').strip())  # enrich paris with the sentence text\n",
    "            pair.set('e1_name', entities[pair.get('e1')])\n",
    "            pair.set('e2_name', entities[pair.get('e2')]) \n",
    "            xml_pairs_el.append(pair)\n",
    "\n",
    "print('pairs: ', len(xml_pairs_el))\n",
    "xml_pair_ids = [p.get('id') for p in xml_pairs_el]\n",
    "print('pair_ids: ', len(xml_pair_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all 1979\n",
      "pos 1461\n",
      "neg 518\n"
     ]
    }
   ],
   "source": [
    "xml_pos_pairs = [p for p in xml_pairs_el if p.get('interaction') == 'True']\n",
    "xml_neg_pairs = [p for p in xml_pairs_el if p.get('interaction') != 'True']\n",
    "print('all', len(xml_pair_ids))\n",
    "print('pos', len(xml_pos_pairs))\n",
    "print('neg', len(xml_neg_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross reference with CSV data source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with both.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('tf_extraction_paper_thomas/TF.GO_enriched2.PMID-jSRE_v2_PD.both.sorted.csv') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    csv_data = [l for l in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3516"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_pairs = {i['pair_id']: i['feedback_PD'] for i in csv_data}\n",
    "len(csv_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1972"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_pairs_in_csv = [p for p in xml_pairs_el if p.get('id') in csv_pairs]\n",
    "len(xml_pairs_in_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1972 ready tagged pairs in the XML that are also present in the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PMID.dPMID7533060.s8.p3',\n",
       " 'PMID.dPMID8100127.s3.p6',\n",
       " 'PMID.dPMID7774103.s6.p3',\n",
       " 'PMID.dPMID19551868.s1.p2',\n",
       " 'PMID.dPMID19526525.s11.p1',\n",
       " 'PMID.dPMID9681824.s0.p9',\n",
       " 'PMID.dPMID1325459.s3.p6']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_pairs_NOT_in_csv = [p for p in xml_pair_ids if p not in csv_pairs]\n",
    "xml_pairs_NOT_in_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these are missing in the _both_ version but are present in _any_\n",
    "### Analyze the available XML data witht he additional info from the Supplement2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  1977  of  1979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['In contrast, ablation of VDR expression enhances FoxO3a phosphorylation, as does knockdown of Sirt1, consistent with the coupling of FoxO acetylation and phosphorylation.',\n",
       " 'Cha, a basic helix-loop-helix transcription factor involved in the regulation of upstream stimulatory factor activity.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_classes(data):\n",
    "    for instance in data:\n",
    "        if instance['class'] == 'TP':\n",
    "            instance['simple_class'] = 'True'\n",
    "        elif instance['class'] == 'FP':\n",
    "            instance['simple_class'] = 'False'\n",
    "        elif instance['class'] == 'NN':\n",
    "            if instance['details'] == 'cooperation/competition in transcription':\n",
    "                instance['simple_class'] = 'True'\n",
    "            else:\n",
    "                instance['simple_class'] = 'False'\n",
    "    return data\n",
    "\n",
    "with open('tf_extraction_paper_thomas/Supplement2.csv', 'r') as f:\n",
    "    suppl2 = simple_classes([l for l in csv.DictReader(f)])\n",
    "\n",
    "suppl2_sents = set([i['sentence'] for i in suppl2])\n",
    "xml_pairs_in_suppl2 = [p for p in xml_pairs_el if p.get('sentence') in suppl2_sents]\n",
    "xml_pairs_not_in_suppl2 = [p for p in xml_pairs_el if p.get('sentence') not in suppl2_sents]\n",
    "print('found ', len(xml_pairs_in_suppl2), ' of ', len(xml_pairs_el))\n",
    "[p.get('sentence') for p in xml_pairs_not_in_suppl2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all sentences are present in the supplements file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  1951  of  1979\n"
     ]
    }
   ],
   "source": [
    "suppl2_sents = set([(i['sentence'], i['simple_class']) for i in suppl2])\n",
    "xml_pairs_in_suppl2 = [p for p in xml_pairs_el if (p.get('sentence'),  p.get('interaction')) in suppl2_sents]\n",
    "xml_pairs_not_in_suppl2 = [p for p in xml_pairs_el if (p.get('sentence'),  p.get('interaction')) not in suppl2_sents]\n",
    "print('found ', len(xml_pairs_in_suppl2), ' of ', len(xml_pairs_el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found  2003  of  2500\n"
     ]
    }
   ],
   "source": [
    "xml_sents = set([(p.get('sentence'),  p.get('interaction')) for p in xml_pairs_el])\n",
    "csv_pairs_in_xml = [i for i in suppl2 if (i['sentence'], i['simple_class']) in xml_sents]\n",
    "csv_pairs_not_in_xml = [i for i in suppl2 if (i['sentence'], i['simple_class']) not in xml_sents]\n",
    "print('found ', len(csv_pairs_in_xml), ' of ', len(suppl2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "p73 Interacts with c-Myc to regulate Y-box-binding protein-1 expression. \n",
      "p73 Interacts with c-Myc to regulate Y-box-binding protein-1 expression.\n",
      "Y-box-binding protein-1 p73\n",
      "Y-box-binding protein-1 p73\n",
      "True False\n",
      "-----\n",
      "Our data suggest that p73 stimulates the transcription of the YB-1 promoter by enhancing recruitment of the c-Myc-Max complex to the E-box \n",
      "Our data suggest that p73 stimulates the transcription of the YB-1 promoter by enhancing recruitment of the c-Myc-Max complex to the E-box\n",
      "YB-1 p73\n",
      "YB-1 p73\n",
      "True False\n",
      "-----\n",
      "Taken together, these findings suggest that Gli, and probably also Gli2, are good candidates for transcriptional activators of the HNF-3beta floor plate enhancer, and the binding site for Gli proteins is a key element for response to Shh signalling. \n",
      "Taken together, these findings suggest that Gli, and probably also Gli2, are good candidates for transcriptional activators of the HNF-3beta floor plate enhancer, and the binding site for Gli proteins is a key element for response to Shh signalling.\n",
      "HNF-3beta Gli\n",
      "HNF-3beta Gli\n",
      "True False\n",
      "-----\n",
      "Taken together, these findings suggest that Gli, and probably also Gli2, are good candidates for transcriptional activators of the HNF-3beta floor plate enhancer, and the binding site for Gli proteins is a key element for response to Shh signalling. \n",
      "Taken together, these findings suggest that Gli, and probably also Gli2, are good candidates for transcriptional activators of the HNF-3beta floor plate enhancer, and the binding site for Gli proteins is a key element for response to Shh signalling.\n",
      "HNF-3beta Gli2\n",
      "HNF-3beta Gli\n",
      "True False\n",
      "-----\n",
      "Induction of c-jun depends on activation of p38-mitogen-activated protein kinase (MAPK) by an AhR-dependent mechanism. \n",
      "Induction of c-jun depends on activation of p38-mitogen-activated protein kinase (MAPK) by an AhR-dependent mechanism.\n",
      "AhR c-jun\n",
      "AhR c-jun\n",
      "False True\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Levenshtein\n",
    "print(len(xml_pairs_not_in_suppl2))\n",
    "found = 0\n",
    "for el in xml_pairs_not_in_suppl2[:5]:\n",
    "    for s in suppl2:\n",
    "        csv_sent, xml_sent = s['sentence'], el.get('sentence')\n",
    "#         dist = Levenshtein.distance(csv_sent, xml_sent)\n",
    "#         if dist < 100:\n",
    "        if csv_sent == xml_sent:\n",
    "            print(csv_sent, '\\n'+ xml_sent)\n",
    "            print(el.get('e1_name'), el.get('e2_name'))\n",
    "            print(s['gene1'], s['gene2'])\n",
    "            print(s['simple_class'], el.get('interaction'))\n",
    "            print('-----')\n",
    "            found += 1\n",
    "            break\n",
    "found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification differs between supplements and ULF. May ULF can be used to annotate the ambigous 1000...\n",
    "\n",
    "### Annotating ambigous supplement2 sentences with ULF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820 of 996 found\n"
     ]
    }
   ],
   "source": [
    "def simple_classes(data):\n",
    "    for instance in data:\n",
    "        if instance['class'] == 'TP':\n",
    "            instance['simple_class'] = 'True'\n",
    "        elif instance['class'] == 'FP':\n",
    "            instance['simple_class'] = 'False'\n",
    "        elif instance['class'] == 'NN':\n",
    "            if instance['details'] == 'cooperation/competition in transcription':\n",
    "                instance['simple_class'] = 'True'\n",
    "            else:\n",
    "                instance['simple_class'] = 'False'\n",
    "    return data\n",
    "\n",
    "with open('tf_extraction_paper_thomas/Supplement2.ambigous.csv', 'r') as f:\n",
    "    ambigous = simple_classes([l for l in csv.DictReader(f)])\n",
    "\n",
    "xml_triples = set([(p.get('sentence'), p.get('e1_name'), p.get('e2_name')) for p in xml_pairs_el])\n",
    "\n",
    "counter = 0\n",
    "for i in ambigous:\n",
    "    triple = (i['sentence'], i['gene1'], i['gene2'])\n",
    "    if triple in xml_triples:\n",
    "        counter +=1\n",
    "    if (triple[0], triple[2], triple[1]) in xml_triples:\n",
    "        counter +=1\n",
    "print(counter, 'of', len(ambigous), 'found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the coding schema of both.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('-->', 401),\n",
       " ('<--', 376),\n",
       " ('', 232),\n",
       " ('c', 178),\n",
       " ('e', 160),\n",
       " ('<->', 59),\n",
       " ('p', 42),\n",
       " ('i', 3),\n",
       " ('b', 2),\n",
       " ('c ', 1)]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "true_c = Counter([csv_pairs[p.get('id')] for p in xml_pairs_in_csv if p.get('interaction') == 'True'])\n",
    "false_c = Counter([csv_pairs[p.get('id')] for p in xml_pairs_in_csv if p.get('interaction') == 'False'])\n",
    "true_c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x', 273),\n",
       " ('', 172),\n",
       " ('w', 37),\n",
       " ('n', 20),\n",
       " ('[4149-->4904, 4609-->4904]', 2),\n",
       " ('[2735-->2735]', 2),\n",
       " ('wrong_Tf, Hos is a cell_line in that context', 2),\n",
       " ('[51176-->51176]', 1),\n",
       " ('[3202-->5241]', 1),\n",
       " ('[4791-->4791, 5970-->4791]', 1),\n",
       " ('[7490-->2297]', 1),\n",
       " ('[3169-->7080, 3170-->7080]', 1),\n",
       " ('b', 1),\n",
       " ('[5914-->5915, 6256-->5915, 7421-->5915]', 1),\n",
       " ('[1385-->2353, 1386-->2353, 1390-->2353]', 1),\n",
       " ('[4149-->7157, 4609-->7157]', 1),\n",
       " ('[3642-->3642]', 1)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_c.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-->', '<--', '', 'c', 'e', '<->', 'p', 'i', 'b', 'c ']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_strings = [i for i, _ in true_c.most_common()]\n",
    "true_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all:  3516\n",
      "pos:  3139\n",
      "neg:  377\n"
     ]
    }
   ],
   "source": [
    "def simple_class_for_bothCSV(data):\n",
    "    for i in data:\n",
    "        if i['feedback_PD'] in ['-->', '<--', '', 'c', 'e', '<->', 'p', 'i', 'b', 'c ']:\n",
    "            i['simple_class'] = 'True'\n",
    "        else:\n",
    "            i['simple_class'] = 'False'\n",
    "    return data\n",
    "\n",
    "simple_csv_data = simple_class_for_bothCSV(csv_data)\n",
    "print('all: ', len(simple_csv_data))\n",
    "print('pos: ', len([i for i in simple_csv_data if i['simple_class'] == 'True']))\n",
    "print('neg: ', len([i for i in simple_csv_data if i['simple_class'] != 'True']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "* `meta.xml` consists of almost 2000 perfectly annotated pairs\n",
    "    * improvement over the 1400 hand annotated subset of `Supplements2.csv`\n",
    "* only ~1400 of these pairs are found in Supplement2 when comparing via the sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
